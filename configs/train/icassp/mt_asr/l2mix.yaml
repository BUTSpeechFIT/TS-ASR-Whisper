# @package _global_
defaults:
  - /train/icassp/mt_asr/base

experiment: lsmix_turbo_v5
model:
  whisper_model: openai/whisper-large-v3-turbo
  reinit_encoder_from: ${oc.env:PRETRAINED_CTC_MODELS_PATH}/${model.whisper_model}_ctc-pretrain_libri/model.safetensors
  mt_num_speakers: 2
  params_to_keep_frozen_keywords:
    - "decoder"

data:
  train_text_norm: "whisper"
  use_timestamps: true
  train_cutsets:
  - ${oc.env:MANIFEST_DIR}/libri2mix_both_100_train_sc_cutset_30s.jsonl.gz
  - ${oc.env:MANIFEST_DIR}/libri2mix_both_360_train_sc_cutset_30s.jsonl.gz
  dev_cutsets: ${oc.env:MANIFEST_DIR}/libri2mix_mix_both_sc_dev_cutset.jsonl.gz
  eval_cutsets: ${oc.env:MANIFEST_DIR}/libri2mix_mix_both_sc_test_cutset.jsonl.gz

training:
  remove_timestamps_from_ctc: true
  eval_strategy: steps
  save_strategy: steps
  eval_steps: 2000
  save_steps: 2000